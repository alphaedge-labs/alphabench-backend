services:
    alphabench__fastapi:
        build:
            context: .
            dockerfile: Dockerfile # Use the main Dockerfile for FastAPI
        image: alphabench__fastapi:latest
        container_name: alphabench__fastapi
        command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
        volumes:
            - .:/app
        ports:
            - "8000:8000"
        environment:
            - ENV_FILE=.env.prod
        env_file:
            - .env.prod
        depends_on:
            - alphabench__postgres
            - alphabench__redis
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - alphabench__network
        deploy:
            resources:
                limits:
                    cpus: "0.7"
                    memory: "1g"
                reservations:
                    cpus: "0.5"
                    memory: "512m"

    celery_worker_script_generator:
        build:
            context: .
            dockerfile: Dockerfile.worker # Use a separate Dockerfile for workers
        container_name: celery_worker_script_generator
        command: celery -A src.infrastructure.queue.celery_app worker --loglevel=info -E --queues=script_generation
        volumes:
            - .:/app
        env_file:
            - .env.prod
        depends_on:
            - alphabench__redis
            - alphabench__postgres
        healthcheck:
            test: ["CMD", "pgrep", "celery"]
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - alphabench__network
        deploy:
            resources:
                limits:
                    cpus: "0.5"
                    memory: "1g"

    celery_worker_script_validator:
        build:
            context: .
            dockerfile: Dockerfile.worker # Use a separate Dockerfile for workers
        container_name: celery_worker_script_validator
        command: celery -A src.infrastructure.queue.celery_app worker --loglevel=info -E --queues=script_validation
        volumes:
            - .:/app
        env_file:
            - .env.prod
        depends_on:
            - alphabench__redis
            - alphabench__postgres
        healthcheck:
            test: ["CMD", "pgrep", "celery"]
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - alphabench__network
        deploy:
            resources:
                limits:
                    cpus: "0.5"
                    memory: "1g"

    celery_worker_backtest:
        build:
            context: .
            dockerfile: Dockerfile.worker # Use a separate Dockerfile for workers
        container_name: celery_worker_backtest
        command: celery -A src.infrastructure.queue.celery_app worker --loglevel=info -E --queues=backtest_execution
        volumes:
            - .:/app
        env_file:
            - .env.prod
        depends_on:
            - alphabench__redis
            - alphabench__postgres
        healthcheck:
            test: ["CMD", "pgrep", "celery"]
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - alphabench__network
        deploy:
            resources:
                limits:
                    cpus: "0.5"
                    memory: "1g"

    celery_worker_report:
        build:
            context: .
            dockerfile: Dockerfile.worker # Use a separate Dockerfile for workers
        container_name: celery_worker_report
        command: celery -A src.infrastructure.queue.celery_app worker --loglevel=info -E --queues=report_generation
        volumes:
            - .:/app
        env_file:
            - .env.prod
        depends_on:
            - alphabench__redis
            - alphabench__postgres
        healthcheck:
            test: ["CMD", "pgrep", "celery"]
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - alphabench__network
        deploy:
            resources:
                limits:
                    cpus: "0.5"
                    memory: "1g"

    celery_beat:
        build:
            context: .
            dockerfile: Dockerfile.worker # Use a separate Dockerfile for workers
        container_name: celery_beat
        command: celery -A src.infrastructure.queue.celery_app beat --loglevel=info
        volumes:
            - .:/app
        env_file:
            - .env.prod
        depends_on:
            - alphabench__redis
        healthcheck:
            test: ["CMD", "pgrep", "celery"]
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - alphabench__network
        deploy:
            resources:
                limits:
                    cpus: "0.1"
                    memory: "128m"

    alphabench__postgres:
        image: timescale/timescaledb:latest-pg15
        container_name: alphabench__postgres
        volumes:
            - postgres_data:/var/lib/postgresql/data
            - ./scripts/001_initial_schema.sql:/docker-entrypoint-initdb.d/001_initial_schema.sql
        environment:
            - POSTGRES_USER=${POSTGRES_USER}
            - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
            - POSTGRES_DB=${POSTGRES_DB}
        ports:
            - "5432:5432"
        healthcheck:
            test:
                [
                    "CMD-SHELL",
                    "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}",
                ]
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - alphabench__network
        deploy:
            resources:
                limits:
                    cpus: "0.5"
                    memory: "1g"

    alphabench__redis:
        image: redis:latest
        container_name: alphabench__redis
        command: redis-server --requirepass ${REDIS_PASSWORD}
        ports:
            - "${REDIS_PORT}:6379"
        environment:
            - REDIS_PASSWORD=${REDIS_PASSWORD}
        healthcheck:
            test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 30s
        restart: always
        volumes:
            - redis_data:/data
        networks:
            - alphabench__network
        deploy:
            resources:
                limits:
                    cpus: "0.2"
                    memory: "256m"

    celery_flower:
        image: mher/flower:latest
        container_name: celery_flower
        command: celery flower --broker=redis://:${REDIS_PASSWORD}@alphabench__redis:6379/0 --port=5555 --persistent=True --enable_events=True
        ports:
            - "5555:5555"
        environment:
            - FLOWER_BASIC_AUTH=admin:password # Optional: Basic authentication
        depends_on:
            - alphabench__redis
        networks:
            - alphabench__network
        deploy:
            resources:
                limits:
                    cpus: "0.1"
                    memory: "128m"

    # alphabench__prometheus:
    #     image: prom/prometheus:v2.44.0
    #     container_name: alphabench__prometheus
    #     volumes:
    #         - ./prometheus:/etc/prometheus
    #         - prometheus_data:/prometheus
    #     command:
    #         - "--config.file=/etc/prometheus/prometheus.yml"
    #     ports:
    #         - "9090:9090"
    #     healthcheck:
    #         test: ["CMD", "wget", "--spider", "http://localhost:9090/-/healthy"]
    #         interval: 30s
    #         timeout: 10s
    #         retries: 3
    #     networks:
    #         - alphabench__network

    # alphabench__grafana:
    #     image: grafana/grafana:9.5.2
    #     container_name: alphabench__grafana
    #     ports:
    #         - "3000:3000"
    #     volumes:
    #         - grafana_data:/var/lib/grafana
    #     healthcheck:
    #         test:
    #             ["CMD", "wget", "--spider", "http://localhost:3000/api/health"]
    #         interval: 30s
    #         timeout: 10s
    #         retries: 3
    #     networks:
    #         - alphabench__network

volumes:
    postgres_data:
    redis_data:
    # prometheus_data:
    # grafana_data:

networks:
    alphabench__network:
        driver: bridge
        external: true
